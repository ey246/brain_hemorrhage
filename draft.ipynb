{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7973a36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f60978a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_fill_mask(mask):\n",
    "    # Ensure mask is a NumPy array\n",
    "    if isinstance(mask, torch.Tensor):\n",
    "        mask = mask.numpy()\n",
    "\n",
    "    mask = mask.astype(np.uint8)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    return mask\n",
    "\n",
    "def apply_windowing(dcm_data, window_center, window_width):\n",
    "    \"\"\"\n",
    "    Apply windowing to a DICOM image.\n",
    "    \n",
    "    :param dcm_data: pydicom Dataset\n",
    "    :param window_center: Center of the window\n",
    "    :param window_width: Width of the window\n",
    "    :return: Windowed image as a numpy array\n",
    "    \"\"\"\n",
    "    intercept = dcm_data.RescaleIntercept if 'RescaleIntercept' in dcm_data else 0\n",
    "    slope = dcm_data.RescaleSlope if 'RescaleSlope' in dcm_data else 1\n",
    "    image = dcm_data.pixel_array * slope + intercept\n",
    "\n",
    "    min_intensity = (window_center - window_width / 2)\n",
    "    max_intensity = (window_center + window_width / 2)\n",
    "\n",
    "    windowed_image = np.clip(image, min_intensity, max_intensity)\n",
    "    windowed_image = ((windowed_image - min_intensity) / (max_intensity - min_intensity)) * 255.0\n",
    "    return windowed_image.astype(np.uint8)\n",
    "\n",
    "class HemorrhagicDataset(Dataset):\n",
    "    def __init__(self, root_dir, csv_file, transform=None, train=True, split_ratio=0.7):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.diagnosis = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Gather all patient directories\n",
    "        self.all_patients = sorted(os.listdir(os.path.join(self.root_dir, \"Patients_CT\")))\n",
    "        \n",
    "        # Split the patient directories into train and validation sets\n",
    "        split_index = int(len(self.all_patients) * split_ratio)\n",
    "        if train:\n",
    "            self.patient_set = self.all_patients[:split_index]\n",
    "        else:\n",
    "            self.patient_set = self.all_patients[split_index:]\n",
    "        \n",
    "        self.slices = self._gather_slices()\n",
    "\n",
    "    def _gather_slices(self):\n",
    "        slices = []\n",
    "        patients_dir = os.path.join(self.root_dir, \"Patients_CT\")\n",
    "        for patient_number in os.listdir(patients_dir):\n",
    "            patient_dir = os.path.join(patients_dir, patient_number, \"brain\")\n",
    "            if os.path.exists(patient_dir):\n",
    "                for file_name in os.listdir(patient_dir):\n",
    "                    if file_name.endswith(\".jpg\") and \"_HGE_Seg\" not in file_name:\n",
    "                        slice_number = file_name.split('.')[0]\n",
    "                        slices.append((patient_dir, patient_number, slice_number))\n",
    "        return slices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_dir, patient_number, slice_number = self.slices[idx]\n",
    "        image_path = os.path.join(patient_dir, f\"{slice_number}.jpg\")\n",
    "        mask_path = os.path.join(patient_dir, f\"{slice_number}_HGE_Seg.jpg\")\n",
    "\n",
    "        # Load the image and mask\n",
    "        image = Image.open(image_path).convert(\"L\")\n",
    "        if os.path.exists(mask_path):\n",
    "            mask = Image.open(mask_path).convert(\"L\")\n",
    "        else:\n",
    "            mask = Image.new(\"L\", image.size)\n",
    "\n",
    "        diag_row = self.diagnosis[(self.diagnosis['PatientNumber'] == int(patient_number))\n",
    "                                  & (self.diagnosis['SliceNumber'] == int(slice_number))]\n",
    "        label = \"hemorrhagic\" if not diag_row.empty and diag_row.iloc[0]['No_Hemorrhage'] == 0 else \"normal\"\n",
    "\n",
    "        # mask = (mask != 0).astype(np.float32)\n",
    "        \n",
    "        # Convert images and masks to PyTorch tensors\n",
    "        image = transforms.ToTensor()(image)\n",
    "        mask = transforms.ToTensor()(mask)\n",
    "\n",
    "        \n",
    "        sample = {'image': image, 'mask': mask, 'label': label, 'original_type': 'image'}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "            sample['mask'] = self.transform(sample['mask'])\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e90c0b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hemo_root_dir = \"computed-tomography-images-for-intracranial-hemorrhage-detection-and-segmentation-1.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "285736e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9761420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = os.path.join(hemo_root_dir, \"hemorrhage_diagnosis.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b567364",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "46bc62c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = os.path.join(hemo_root_dir, \"hemorrhage_diagnosis.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e90c0b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hemo_val_dataset = HemorrhagicDataset(root_dir=hemo_root_dir, csv_file=csv_file, transform=transform, train=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
